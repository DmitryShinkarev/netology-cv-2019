{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "HW ConvNets",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "13UvorM_Xg0v",
        "colab_type": "text"
      },
      "source": [
        "# Deep learning for computer vision\n",
        "\n",
        "\n",
        "This notebook will teach you to build and train convolutional networks for image recognition. Brace yourselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeckRQLaXg00",
        "colab_type": "text"
      },
      "source": [
        "# Ð¡ifar 10 dataset\n",
        "This week, we shall focus on the image recognition problem on Cifar 10 dataset\n",
        "* 50k images of shape 3x32x32\n",
        "* 10 different classes (see examples)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8s1fqyQXg02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "# if you're running in colab, go to Runtime -> Change Runtimy Type -> GPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xus1MbrsXg1C",
        "colab_type": "code",
        "outputId": "57f45275-2ea5-4e45-c781-0998c6bb14c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                       download=True, transform=transforms.ToTensor())\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                            download=True, transform=transforms.ToTensor())\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [40000, 10000])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdRZpZgpXg1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 50\n",
        "train_batch_gen = torch.utils.data.DataLoader(train_dataset, \n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCwafGk3Xg1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_batch_gen = torch.utils.data.DataLoader(val_dataset, \n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x93pqtAWkOxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_batch_gen = torch.utils.data.DataLoader(test_dataset, \n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8SodWq1Xg1K",
        "colab_type": "text"
      },
      "source": [
        "## Image examples ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMmK0-gQXg1L",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://i.ibb.co/1JZV1Rw/2019-10-26-13-47-29.png\" alt=\"2019-10-26-13-47-29\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1_QD7yDXg1M",
        "colab_type": "text"
      },
      "source": [
        "# Building a network\n",
        "\n",
        "Simple neural networks with layers applied on top of one another can be implemented as `torch.nn.Sequential` - just add a list of pre-built modules and let it train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7R95tJnXg1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# a special module that converts [batch, channel, w, h] to [batch, units]\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvARkyxoXg1P",
        "colab_type": "text"
      },
      "source": [
        "Let's start with a dense network for our baseline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaIHqiVpXg1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential()\n",
        "\n",
        "# reshape from \"images\" to flat vectors\n",
        "model.add_module('flatten', Flatten())\n",
        "\n",
        "# dense \"head\"\n",
        "model.add_module('dense1', nn.Linear(3072, 1064))\n",
        "model.add_module('dense0_relu', nn.ReLU())\n",
        "model.add_module('dense2', nn.Linear(1064, 512))\n",
        "model.add_module('dropout0', nn.Dropout(0.05)) \n",
        "model.add_module('dense1_relu', nn.ReLU())\n",
        "model.add_module('dense3', nn.Linear(512, 256))\n",
        "model.add_module('dropout1', nn.Dropout(0.05))\n",
        "model.add_module('dense2_relu', nn.ReLU())\n",
        "model.add_module('dense4', nn.Linear(256, 64))\n",
        "model.add_module('dropout2', nn.Dropout(0.05))\n",
        "model.add_module('dense3_relu', nn.ReLU())\n",
        "model.add_module('dense2_logits', nn.Linear(64, 200)) # logits for 200 classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_XK4tMwXg1R",
        "colab_type": "text"
      },
      "source": [
        "As in our basic tutorial, we train our model with negative log-likelihood aka crossentropy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVoloCu3Xg1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_loss(X_batch, y_batch):\n",
        "    X_batch = Variable(torch.FloatTensor(X_batch)).cuda()\n",
        "    y_batch = Variable(torch.LongTensor(y_batch)).cuda()\n",
        "    logits = model.cuda()(X_batch)\n",
        "    return F.cross_entropy(logits, y_batch).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wfNHgjZXg1U",
        "colab_type": "text"
      },
      "source": [
        "### Training on minibatches\n",
        "* We got 50k images, that's way too many for a full-batch SGD. Let's train on minibatches instead\n",
        "* Below is a function that splits the training sample into minibatches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwMPL3_PXg1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "train_loss_dense = []\n",
        "val_accuracy_dense = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eQoW1iSXg1W",
        "colab_type": "code",
        "outputId": "3ce2b66f-cdfb-48ea-9e99-482295508dc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "num_epochs = 50 # total amount of full passes over training data\n",
        "\n",
        "import time\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "    model.train(True) # enable dropout / batch_norm training behavior\n",
        "    for (X_batch, y_batch) in train_batch_gen:\n",
        "        # train on batch\n",
        "        loss = compute_loss(X_batch, y_batch)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        train_loss_dense.append(loss.cpu().data.numpy())\n",
        "    \n",
        "    model.train(False) # disable dropout / use averages for batch_norm\n",
        "    for X_batch, y_batch in val_batch_gen:\n",
        "        logits = model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
        "        y_pred = logits.max(1)[1].data\n",
        "        val_accuracy_dense.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
        "\n",
        "    \n",
        "    # Then we print the results for this epoch:\n",
        "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
        "        epoch + 1, num_epochs, time.time() - start_time))\n",
        "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
        "        np.mean(train_loss_dense[-len(train_dataset) // batch_size :])))\n",
        "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
        "        np.mean(val_accuracy_dense[-len(val_dataset) // batch_size :]) * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 of 50 took 17.202s\n",
            "  training loss (in-iteration): \t2.932337\n",
            "  validation accuracy: \t\t\t10.08 %\n",
            "Epoch 2 of 50 took 11.809s\n",
            "  training loss (in-iteration): \t2.318467\n",
            "  validation accuracy: \t\t\t16.00 %\n",
            "Epoch 3 of 50 took 11.818s\n",
            "  training loss (in-iteration): \t2.157540\n",
            "  validation accuracy: \t\t\t18.65 %\n",
            "Epoch 4 of 50 took 11.784s\n",
            "  training loss (in-iteration): \t2.086789\n",
            "  validation accuracy: \t\t\t22.91 %\n",
            "Epoch 5 of 50 took 11.876s\n",
            "  training loss (in-iteration): \t2.043582\n",
            "  validation accuracy: \t\t\t23.24 %\n",
            "Epoch 6 of 50 took 11.786s\n",
            "  training loss (in-iteration): \t1.982003\n",
            "  validation accuracy: \t\t\t28.05 %\n",
            "Epoch 7 of 50 took 11.782s\n",
            "  training loss (in-iteration): \t1.924198\n",
            "  validation accuracy: \t\t\t31.56 %\n",
            "Epoch 8 of 50 took 11.719s\n",
            "  training loss (in-iteration): \t1.884079\n",
            "  validation accuracy: \t\t\t32.36 %\n",
            "Epoch 9 of 50 took 11.635s\n",
            "  training loss (in-iteration): \t1.850280\n",
            "  validation accuracy: \t\t\t33.05 %\n",
            "Epoch 10 of 50 took 11.715s\n",
            "  training loss (in-iteration): \t1.808998\n",
            "  validation accuracy: \t\t\t34.92 %\n",
            "Epoch 11 of 50 took 11.971s\n",
            "  training loss (in-iteration): \t1.777004\n",
            "  validation accuracy: \t\t\t36.29 %\n",
            "Epoch 12 of 50 took 11.749s\n",
            "  training loss (in-iteration): \t1.743350\n",
            "  validation accuracy: \t\t\t37.76 %\n",
            "Epoch 13 of 50 took 11.854s\n",
            "  training loss (in-iteration): \t1.714684\n",
            "  validation accuracy: \t\t\t38.96 %\n",
            "Epoch 14 of 50 took 11.678s\n",
            "  training loss (in-iteration): \t1.686786\n",
            "  validation accuracy: \t\t\t40.66 %\n",
            "Epoch 15 of 50 took 11.861s\n",
            "  training loss (in-iteration): \t1.656919\n",
            "  validation accuracy: \t\t\t41.51 %\n",
            "Epoch 16 of 50 took 11.753s\n",
            "  training loss (in-iteration): \t1.630227\n",
            "  validation accuracy: \t\t\t41.48 %\n",
            "Epoch 17 of 50 took 11.690s\n",
            "  training loss (in-iteration): \t1.606533\n",
            "  validation accuracy: \t\t\t43.42 %\n",
            "Epoch 18 of 50 took 11.828s\n",
            "  training loss (in-iteration): \t1.580079\n",
            "  validation accuracy: \t\t\t44.02 %\n",
            "Epoch 19 of 50 took 11.604s\n",
            "  training loss (in-iteration): \t1.559885\n",
            "  validation accuracy: \t\t\t43.70 %\n",
            "Epoch 20 of 50 took 11.655s\n",
            "  training loss (in-iteration): \t1.537315\n",
            "  validation accuracy: \t\t\t43.24 %\n",
            "Epoch 21 of 50 took 11.703s\n",
            "  training loss (in-iteration): \t1.517319\n",
            "  validation accuracy: \t\t\t41.38 %\n",
            "Epoch 22 of 50 took 11.616s\n",
            "  training loss (in-iteration): \t1.496033\n",
            "  validation accuracy: \t\t\t46.77 %\n",
            "Epoch 23 of 50 took 11.776s\n",
            "  training loss (in-iteration): \t1.474251\n",
            "  validation accuracy: \t\t\t46.14 %\n",
            "Epoch 24 of 50 took 11.650s\n",
            "  training loss (in-iteration): \t1.455192\n",
            "  validation accuracy: \t\t\t48.30 %\n",
            "Epoch 25 of 50 took 11.606s\n",
            "  training loss (in-iteration): \t1.438182\n",
            "  validation accuracy: \t\t\t49.55 %\n",
            "Epoch 26 of 50 took 11.659s\n",
            "  training loss (in-iteration): \t1.420184\n",
            "  validation accuracy: \t\t\t50.02 %\n",
            "Epoch 27 of 50 took 11.718s\n",
            "  training loss (in-iteration): \t1.399240\n",
            "  validation accuracy: \t\t\t46.19 %\n",
            "Epoch 28 of 50 took 11.770s\n",
            "  training loss (in-iteration): \t1.381605\n",
            "  validation accuracy: \t\t\t48.55 %\n",
            "Epoch 29 of 50 took 11.737s\n",
            "  training loss (in-iteration): \t1.367335\n",
            "  validation accuracy: \t\t\t50.20 %\n",
            "Epoch 30 of 50 took 11.629s\n",
            "  training loss (in-iteration): \t1.352049\n",
            "  validation accuracy: \t\t\t50.94 %\n",
            "Epoch 31 of 50 took 11.809s\n",
            "  training loss (in-iteration): \t1.332025\n",
            "  validation accuracy: \t\t\t51.32 %\n",
            "Epoch 32 of 50 took 11.855s\n",
            "  training loss (in-iteration): \t1.317377\n",
            "  validation accuracy: \t\t\t52.45 %\n",
            "Epoch 33 of 50 took 11.905s\n",
            "  training loss (in-iteration): \t1.301902\n",
            "  validation accuracy: \t\t\t52.28 %\n",
            "Epoch 34 of 50 took 11.697s\n",
            "  training loss (in-iteration): \t1.283828\n",
            "  validation accuracy: \t\t\t54.46 %\n",
            "Epoch 35 of 50 took 11.715s\n",
            "  training loss (in-iteration): \t1.270539\n",
            "  validation accuracy: \t\t\t55.17 %\n",
            "Epoch 36 of 50 took 11.645s\n",
            "  training loss (in-iteration): \t1.255153\n",
            "  validation accuracy: \t\t\t55.17 %\n",
            "Epoch 37 of 50 took 11.893s\n",
            "  training loss (in-iteration): \t1.241146\n",
            "  validation accuracy: \t\t\t56.32 %\n",
            "Epoch 38 of 50 took 11.802s\n",
            "  training loss (in-iteration): \t1.228305\n",
            "  validation accuracy: \t\t\t57.42 %\n",
            "Epoch 39 of 50 took 11.961s\n",
            "  training loss (in-iteration): \t1.212915\n",
            "  validation accuracy: \t\t\t58.31 %\n",
            "Epoch 40 of 50 took 11.719s\n",
            "  training loss (in-iteration): \t1.198331\n",
            "  validation accuracy: \t\t\t58.34 %\n",
            "Epoch 41 of 50 took 11.688s\n",
            "  training loss (in-iteration): \t1.182325\n",
            "  validation accuracy: \t\t\t55.72 %\n",
            "Epoch 42 of 50 took 11.811s\n",
            "  training loss (in-iteration): \t1.163640\n",
            "  validation accuracy: \t\t\t58.76 %\n",
            "Epoch 43 of 50 took 11.715s\n",
            "  training loss (in-iteration): \t1.153257\n",
            "  validation accuracy: \t\t\t58.33 %\n",
            "Epoch 44 of 50 took 11.865s\n",
            "  training loss (in-iteration): \t1.142804\n",
            "  validation accuracy: \t\t\t58.17 %\n",
            "Epoch 45 of 50 took 11.711s\n",
            "  training loss (in-iteration): \t1.125969\n",
            "  validation accuracy: \t\t\t59.35 %\n",
            "Epoch 46 of 50 took 11.736s\n",
            "  training loss (in-iteration): \t1.109590\n",
            "  validation accuracy: \t\t\t59.72 %\n",
            "Epoch 47 of 50 took 11.855s\n",
            "  training loss (in-iteration): \t1.096896\n",
            "  validation accuracy: \t\t\t55.84 %\n",
            "Epoch 48 of 50 took 11.678s\n",
            "  training loss (in-iteration): \t1.079762\n",
            "  validation accuracy: \t\t\t62.67 %\n",
            "Epoch 49 of 50 took 11.718s\n",
            "  training loss (in-iteration): \t1.067164\n",
            "  validation accuracy: \t\t\t60.18 %\n",
            "Epoch 50 of 50 took 11.780s\n",
            "  training loss (in-iteration): \t1.052885\n",
            "  validation accuracy: \t\t\t62.23 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA_G9U8cXg1X",
        "colab_type": "text"
      },
      "source": [
        "Don't wait for full 100 epochs. You can interrupt training after 5-20 epochs once validation accuracy stops going up.\n",
        "\n",
        "### Final test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhX-E0IEXg1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.train(False) # disable dropout / use averages for batch_norm\n",
        "test_batch_acc = []\n",
        "for X_batch, y_batch in test_batch_gen:\n",
        "    logits = model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
        "    y_pred = logits.max(1)[1].data\n",
        "    test_batch_acc.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
        "\n",
        "\n",
        "test_accuracy = np.mean(test_batch_acc)\n",
        "    \n",
        "print(\"Final results:\")\n",
        "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
        "    test_accuracy * 100))\n",
        "\n",
        "if test_accuracy * 100 > 70:\n",
        "    print(\"U'r freakin' amazin'!\")\n",
        "elif test_accuracy * 100 > 50:\n",
        "    print(\"Achievement unlocked: 110lvl Warlock!\")\n",
        "elif test_accuracy * 100 > 40:\n",
        "    print(\"Achievement unlocked: 80lvl Warlock!\")\n",
        "elif test_accuracy * 100 > 30:\n",
        "    print(\"Achievement unlocked: 70lvl Warlock!\")\n",
        "elif test_accuracy * 100 > 20:\n",
        "    print(\"Achievement unlocked: 60lvl Warlock!\")\n",
        "else:\n",
        "    print(\"We need more magic! Follow instructons below\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZoG6CpdXg1Z",
        "colab_type": "text"
      },
      "source": [
        "## Task I: small convolution net\n",
        "### First step\n",
        "\n",
        "Let's create a mini-convolutional network with roughly such architecture:\n",
        "* Input layer\n",
        "* 3x3 convolution with 128 filters and _ReLU_ activation\n",
        "* 2x2 pooling (or set previous convolution stride to 3)\n",
        "* Flatten\n",
        "* Dense layer with 1024 neurons and _ReLU_ activation\n",
        "* 30% dropout\n",
        "* Output dense layer.\n",
        "\n",
        "\n",
        "__Convolutional layers__ in torch are just like all other layers, but with a specific set of parameters:\n",
        "\n",
        "__`...`__\n",
        "\n",
        "__`model.add_module('conv1', nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3)) # convolution`__\n",
        "\n",
        "__`model.add_module('pool1', nn.MaxPool2d(2)) # max pooling 2x2`__\n",
        "\n",
        "__`...`__\n",
        "\n",
        "\n",
        "Once you're done (and compute_loss no longer raises errors), train it with __Adam__ optimizer with default params (feel free to modify the code above).\n",
        "\n",
        "If everything is right, you should get at least __50%__ validation accuracy.\n",
        "\n",
        "__HACK_OF_THE_DAY__ :the number of channels must be in the order of the number of class_labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_Vxxz8FXg1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential()\n",
        "\n",
        "model.add_module('conv1', nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3))\n",
        "model.add_module('pool1', nn.MaxPool2d(2))\n",
        "model.add_module('relu1', nn.ReLU())\n",
        "model.add_module('conv2', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3))\n",
        "model.add_module('pool2', nn.MaxPool2d(2))\n",
        "model.add_module('relu2', nn.ReLU())\n",
        "model.add_module('conv3', nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3))\n",
        "model.add_module('pool3', nn.MaxPool2d(2))\n",
        "model.add_module('relu3', nn.ReLU())\n",
        "model.add_module('flatten', Flatten())\n",
        "model.add_module('dense0', nn.Linear(2048, 1024))\n",
        "model.add_module('relu', nn.ReLU())\n",
        "model.add_module('dropout', nn.Dropout(0.3))\n",
        "model.add_module('dense1_logits', nn.Linear(1024, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfKEp5lFXg1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "train_loss_conv = []\n",
        "val_accuracy_conv = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGDyORKIXg1c",
        "colab_type": "code",
        "outputId": "68dffe1a-bdff-4c45-993f-969a4c4b4e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        }
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(model.cuda(), (3, 32, 32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 128, 30, 30]           3,584\n",
            "         MaxPool2d-2          [-1, 128, 15, 15]               0\n",
            "              ReLU-3          [-1, 128, 15, 15]               0\n",
            "            Conv2d-4          [-1, 256, 13, 13]         295,168\n",
            "         MaxPool2d-5            [-1, 256, 6, 6]               0\n",
            "              ReLU-6            [-1, 256, 6, 6]               0\n",
            "            Conv2d-7            [-1, 512, 4, 4]       1,180,160\n",
            "         MaxPool2d-8            [-1, 512, 2, 2]               0\n",
            "              ReLU-9            [-1, 512, 2, 2]               0\n",
            "          Flatten-10                 [-1, 2048]               0\n",
            "           Linear-11                 [-1, 1024]       2,098,176\n",
            "             ReLU-12                 [-1, 1024]               0\n",
            "          Dropout-13                 [-1, 1024]               0\n",
            "           Linear-14                   [-1, 10]          10,250\n",
            "================================================================\n",
            "Total params: 3,587,338\n",
            "Trainable params: 3,587,338\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.92\n",
            "Params size (MB): 13.68\n",
            "Estimated Total Size (MB): 15.62\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13HBzIq5Xg1d",
        "colab_type": "text"
      },
      "source": [
        "## retrain it ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAPIaznAXg1e",
        "colab_type": "code",
        "outputId": "ea2732d1-159f-41cf-a7e4-02067ce265d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "num_epochs = 100 # total amount of full passes over training data\n",
        "batch_size = 50  # number of samples processed in one SGD iteration\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print (num_epochs)\n",
        "    # In each epoch, we do a full pass over the training data:\n",
        "    start_time = time.time()\n",
        "    model.train(True) # enable dropout / batch_norm training behavior\n",
        "    for (X_batch, y_batch) in train_batch_gen:\n",
        "        # train on batch\n",
        "        loss = compute_loss(X_batch, y_batch)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        train_loss_conv.append(loss.data.cpu().numpy())\n",
        "    print (num_epochs)    \n",
        "    model.train(False) # disable dropout / use averages for batch_norm\n",
        "    for X_batch, y_batch in val_batch_gen:\n",
        "        logits = model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
        "        y_pred = logits.max(1)[1].data\n",
        "        val_accuracy_conv.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
        "\n",
        "    print (num_epochs)\n",
        "    # Then we print the results for this epoch:\n",
        "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
        "        epoch + 1, num_epochs, time.time() - start_time))\n",
        "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
        "        np.mean(train_loss_conv[-len(train_dataset) // batch_size :])))\n",
        "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
        "        np.mean(val_accuracy_conv[-len(val_dataset) // batch_size :]) * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "100\n",
            "100\n",
            "Epoch 1 of 100 took 18.964s\n",
            "  training loss (in-iteration): \t2.288642\n",
            "  validation accuracy: \t\t\t19.68 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 2 of 100 took 18.822s\n",
            "  training loss (in-iteration): \t2.105922\n",
            "  validation accuracy: \t\t\t24.93 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 3 of 100 took 18.894s\n",
            "  training loss (in-iteration): \t1.950737\n",
            "  validation accuracy: \t\t\t30.71 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 4 of 100 took 18.913s\n",
            "  training loss (in-iteration): \t1.816284\n",
            "  validation accuracy: \t\t\t33.90 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 5 of 100 took 19.018s\n",
            "  training loss (in-iteration): \t1.685271\n",
            "  validation accuracy: \t\t\t40.65 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 6 of 100 took 18.871s\n",
            "  training loss (in-iteration): \t1.594859\n",
            "  validation accuracy: \t\t\t41.27 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 7 of 100 took 18.914s\n",
            "  training loss (in-iteration): \t1.529277\n",
            "  validation accuracy: \t\t\t45.10 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 8 of 100 took 18.995s\n",
            "  training loss (in-iteration): \t1.467734\n",
            "  validation accuracy: \t\t\t46.39 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 9 of 100 took 18.822s\n",
            "  training loss (in-iteration): \t1.410510\n",
            "  validation accuracy: \t\t\t49.99 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 10 of 100 took 18.904s\n",
            "  training loss (in-iteration): \t1.355666\n",
            "  validation accuracy: \t\t\t53.04 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 11 of 100 took 18.866s\n",
            "  training loss (in-iteration): \t1.307327\n",
            "  validation accuracy: \t\t\t54.92 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 12 of 100 took 18.838s\n",
            "  training loss (in-iteration): \t1.260118\n",
            "  validation accuracy: \t\t\t56.66 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 13 of 100 took 19.011s\n",
            "  training loss (in-iteration): \t1.215587\n",
            "  validation accuracy: \t\t\t59.73 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 14 of 100 took 18.728s\n",
            "  training loss (in-iteration): \t1.175085\n",
            "  validation accuracy: \t\t\t60.81 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 15 of 100 took 18.870s\n",
            "  training loss (in-iteration): \t1.135303\n",
            "  validation accuracy: \t\t\t60.75 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 16 of 100 took 18.837s\n",
            "  training loss (in-iteration): \t1.099351\n",
            "  validation accuracy: \t\t\t61.92 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 17 of 100 took 18.840s\n",
            "  training loss (in-iteration): \t1.065929\n",
            "  validation accuracy: \t\t\t62.29 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 18 of 100 took 18.833s\n",
            "  training loss (in-iteration): \t1.029013\n",
            "  validation accuracy: \t\t\t60.61 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 19 of 100 took 18.826s\n",
            "  training loss (in-iteration): \t0.995900\n",
            "  validation accuracy: \t\t\t68.24 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 20 of 100 took 18.818s\n",
            "  training loss (in-iteration): \t0.961680\n",
            "  validation accuracy: \t\t\t68.99 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 21 of 100 took 18.842s\n",
            "  training loss (in-iteration): \t0.927969\n",
            "  validation accuracy: \t\t\t70.00 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 22 of 100 took 18.809s\n",
            "  training loss (in-iteration): \t0.899296\n",
            "  validation accuracy: \t\t\t70.11 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 23 of 100 took 18.872s\n",
            "  training loss (in-iteration): \t0.865686\n",
            "  validation accuracy: \t\t\t71.51 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 24 of 100 took 18.896s\n",
            "  training loss (in-iteration): \t0.838415\n",
            "  validation accuracy: \t\t\t72.41 %\n",
            "100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-406460ba66f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtrain_loss_conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# disable dropout / use averages for batch_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9cz0cWcXg1f",
        "colab_type": "text"
      },
      "source": [
        "__Hint:__ If you don't want to compute shapes by hand, just plug in any shape (e.g. 1 unit) and run compute_loss. You will see something like this:\n",
        "\n",
        "__`RuntimeError: size mismatch, m1: [5 x 1960], m2: [1 x 64] at /some/long/path/to/torch/operation`__\n",
        "\n",
        "See the __1960__ there? That's your actual input shape.\n",
        "\n",
        "## Task 2: adding normalization\n",
        "\n",
        "* Add batch norm (with default params) between convolution and ReLU\n",
        "  * nn.BatchNorm*d (1d for dense, 2d for conv)\n",
        "  * usually better to put them after linear/conv but before nonlinearity\n",
        "* Re-train the network with the same optimizer, it should get at least 20% validation accuracy at peak.\n",
        "\n",
        "To know more about **batch_norm** and **data covariate shift**\n",
        "\n",
        "https://towardsdatascience.com/batch-normalization-in-neural-networks-1ac91516821c\n",
        "\n",
        "https://www.youtube.com/watch?v=nUUqwaxLnWs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-zChqvnXg1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential()\n",
        "\n",
        "model.add_module('conv1', nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3))\n",
        "model.add_module('pool1', nn.MaxPool2d(2))\n",
        "model.add_module('bn1', nn.BatchNorm2d(128))\n",
        "model.add_module('relu1', nn.ReLU())\n",
        "model.add_module('conv2', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3))\n",
        "model.add_module('pool2', nn.MaxPool2d(2))\n",
        "model.add_module('bn2', nn.BatchNorm2d(256))\n",
        "model.add_module('relu2', nn.ReLU())\n",
        "model.add_module('conv3', nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3))\n",
        "model.add_module('pool3', nn.MaxPool2d(2))\n",
        "model.add_module('bn3', nn.BatchNorm2d(512))\n",
        "model.add_module('relu3', nn.ReLU())\n",
        "model.add_module('flatten', Flatten())\n",
        "model.add_module('dense0', nn.Linear(2048, 1024))\n",
        "model.add_module('relu', nn.ReLU())\n",
        "model.add_module('dropout', nn.Dropout(0.3))\n",
        "model.add_module('dense1_logits', nn.Linear(1024, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfeDDb4dXg1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "train_loss_batchnorm = []\n",
        "val_accuracy_batchnorm = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owQz4agnXg1j",
        "colab_type": "code",
        "outputId": "0e0c82b2-f141-4fb4-8e86-b65246f95b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "num_epochs = 100 # total amount of full passes over training data\n",
        "batch_size = 50  # number of samples processed in one SGD iteration\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print (num_epochs)\n",
        "    # In each epoch, we do a full pass over the training data:\n",
        "    start_time = time.time()\n",
        "    model.train(True) # enable dropout / batch_norm training behavior\n",
        "    for (X_batch, y_batch) in train_batch_gen:\n",
        "        # train on batch\n",
        "        loss = compute_loss(X_batch, y_batch)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        train_loss_batchnorm.append(loss.data.cpu().numpy())\n",
        "    print (num_epochs)    \n",
        "    model.train(False) # disable dropout / use averages for batch_norm\n",
        "    for X_batch, y_batch in val_batch_gen:\n",
        "        logits = model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
        "        y_pred = logits.max(1)[1].data\n",
        "        val_accuracy_batchnorm.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
        "\n",
        "    print (num_epochs)\n",
        "    # Then we print the results for this epoch:\n",
        "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
        "        epoch + 1, num_epochs, time.time() - start_time))\n",
        "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
        "        np.mean(train_loss_batchnorm[-len(train_dataset) // batch_size :])))\n",
        "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
        "        np.mean(val_accuracy_batchnorm[-len(val_dataset) // batch_size :]) * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "100\n",
            "100\n",
            "Epoch 1 of 100 took 19.844s\n",
            "  training loss (in-iteration): \t1.450463\n",
            "  validation accuracy: \t\t\t62.64 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 2 of 100 took 19.681s\n",
            "  training loss (in-iteration): \t1.003344\n",
            "  validation accuracy: \t\t\t70.33 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 3 of 100 took 19.625s\n",
            "  training loss (in-iteration): \t0.794788\n",
            "  validation accuracy: \t\t\t75.12 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 4 of 100 took 19.646s\n",
            "  training loss (in-iteration): \t0.636117\n",
            "  validation accuracy: \t\t\t79.39 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 5 of 100 took 19.604s\n",
            "  training loss (in-iteration): \t0.504999\n",
            "  validation accuracy: \t\t\t84.88 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 6 of 100 took 19.643s\n",
            "  training loss (in-iteration): \t0.379702\n",
            "  validation accuracy: \t\t\t86.47 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 7 of 100 took 19.685s\n",
            "  training loss (in-iteration): \t0.268184\n",
            "  validation accuracy: \t\t\t90.49 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 8 of 100 took 19.744s\n",
            "  training loss (in-iteration): \t0.180867\n",
            "  validation accuracy: \t\t\t89.74 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 9 of 100 took 19.616s\n",
            "  training loss (in-iteration): \t0.117786\n",
            "  validation accuracy: \t\t\t94.17 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 10 of 100 took 19.617s\n",
            "  training loss (in-iteration): \t0.074992\n",
            "  validation accuracy: \t\t\t94.53 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 11 of 100 took 19.638s\n",
            "  training loss (in-iteration): \t0.046195\n",
            "  validation accuracy: \t\t\t95.24 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 12 of 100 took 19.743s\n",
            "  training loss (in-iteration): \t0.029941\n",
            "  validation accuracy: \t\t\t95.29 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 13 of 100 took 19.634s\n",
            "  training loss (in-iteration): \t0.022315\n",
            "  validation accuracy: \t\t\t95.34 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 14 of 100 took 19.820s\n",
            "  training loss (in-iteration): \t0.015484\n",
            "  validation accuracy: \t\t\t95.39 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 15 of 100 took 19.754s\n",
            "  training loss (in-iteration): \t0.011384\n",
            "  validation accuracy: \t\t\t95.32 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 16 of 100 took 19.703s\n",
            "  training loss (in-iteration): \t0.009065\n",
            "  validation accuracy: \t\t\t95.44 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 17 of 100 took 19.686s\n",
            "  training loss (in-iteration): \t0.007492\n",
            "  validation accuracy: \t\t\t95.42 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 18 of 100 took 19.707s\n",
            "  training loss (in-iteration): \t0.005910\n",
            "  validation accuracy: \t\t\t95.52 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 19 of 100 took 19.647s\n",
            "  training loss (in-iteration): \t0.005453\n",
            "  validation accuracy: \t\t\t95.36 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 20 of 100 took 19.720s\n",
            "  training loss (in-iteration): \t0.004434\n",
            "  validation accuracy: \t\t\t95.47 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 21 of 100 took 19.682s\n",
            "  training loss (in-iteration): \t0.003695\n",
            "  validation accuracy: \t\t\t95.40 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 22 of 100 took 19.703s\n",
            "  training loss (in-iteration): \t0.003243\n",
            "  validation accuracy: \t\t\t95.45 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 23 of 100 took 19.718s\n",
            "  training loss (in-iteration): \t0.002816\n",
            "  validation accuracy: \t\t\t95.54 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 24 of 100 took 19.685s\n",
            "  training loss (in-iteration): \t0.002763\n",
            "  validation accuracy: \t\t\t95.63 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 25 of 100 took 19.599s\n",
            "  training loss (in-iteration): \t0.002429\n",
            "  validation accuracy: \t\t\t95.56 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 26 of 100 took 19.674s\n",
            "  training loss (in-iteration): \t0.002094\n",
            "  validation accuracy: \t\t\t95.54 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 27 of 100 took 19.721s\n",
            "  training loss (in-iteration): \t0.002365\n",
            "  validation accuracy: \t\t\t95.48 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 28 of 100 took 19.637s\n",
            "  training loss (in-iteration): \t0.002012\n",
            "  validation accuracy: \t\t\t95.48 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 29 of 100 took 19.783s\n",
            "  training loss (in-iteration): \t0.001940\n",
            "  validation accuracy: \t\t\t95.50 %\n",
            "100\n",
            "100\n",
            "100\n",
            "Epoch 30 of 100 took 20.031s\n",
            "  training loss (in-iteration): \t0.001971\n",
            "  validation accuracy: \t\t\t95.46 %\n",
            "100\n",
            "100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-6ca88f3a84c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mval_accuracy_batchnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujsQDVjCXg1k",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Task 3: Data Augmentation\n",
        "\n",
        "**Augmenti - A spell used to produce water from a wand (Harry Potter Wiki)**\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/Practical_DL/blob/spring2019/week03_convnets/HagridsHut_PM_B6C28_Hagrid_sHutFireHarryFang.jpg?raw=1\" style=\"width:80%\">\n",
        "\n",
        "There's a powerful torch tool for image preprocessing useful to do data preprocessing and augmentation.\n",
        "\n",
        "Here's how it works: we define a pipeline that\n",
        "* makes random crops of data (augmentation)\n",
        "* randomly flips image horizontally (augmentation)\n",
        "* then normalizes it (preprocessing)\n",
        "* and casts to tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYzmHjokXg1k",
        "colab_type": "text"
      },
      "source": [
        "When testing, we don't need random crops, just normalize with same statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFO4_dGRXg1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "means = np.array((0.4914, 0.4822, 0.4465))\n",
        "stds = np.array((0.2023, 0.1994, 0.2010))\n",
        "\n",
        "transform_augment = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(means, stds)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4h7DKamXg1m",
        "colab_type": "code",
        "outputId": "fb149dea-8b2c-43be-dc17-5d726e770d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        }
      },
      "source": [
        "augmented_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                       download=True, transform=transform_augment)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ40VVStr5gr",
        "colab_type": "code",
        "outputId": "95ba94a6-5130-4fcd-efe1-0c1fb0436241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "# Here we unnormalize data to make them look pretty\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    frog = augmented_dataset[0][0]\n",
        "    unnormalized = frog.permute(1, 2, 0).numpy() * stds + means\n",
        "    clipped = np.clip(unnormalized, 0, 1)\n",
        "    plt.imshow(clipped)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABDkAAAExCAYAAAB25XneAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAjc5AAAAAADAROAmBwAAAAAAmAj/H4RcEpSzg6FbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1440x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4C1aKIFtXwN",
        "colab_type": "text"
      },
      "source": [
        "You see?) Some of the frogs got flipped!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pxU3h0tioG7l",
        "colab": {}
      },
      "source": [
        "train_dataset, val_dataset = torch.utils.data.random_split(augmented_dataset, [40000, 10000])\n",
        "\n",
        "# But we can not apply augmentations on validation dataset\n",
        "from copy import deepcopy\n",
        "val_dataset.dataset = deepcopy(val_dataset.dataset)\n",
        "val_dataset.dataset.transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(means, stds)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H-lhSvFWoG7p",
        "colab": {}
      },
      "source": [
        "batch_size = 50\n",
        "train_batch_gen = torch.utils.data.DataLoader(train_dataset, \n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fhZyb-UeoG7r",
        "colab": {}
      },
      "source": [
        "val_batch_gen = torch.utils.data.DataLoader(val_dataset, \n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kgsENWxyrQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IMPORTANT: Reinitialize your model from the previous exercise\n",
        "\n",
        "model = nn.Sequential()\n",
        "\n",
        "model.add_module('conv1', nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3))\n",
        "model.add_module('pool1', nn.MaxPool2d(2))\n",
        "model.add_module('bn1', nn.BatchNorm2d(128))\n",
        "model.add_module('relu1', nn.ReLU())\n",
        "model.add_module('conv2', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3))\n",
        "model.add_module('pool2', nn.MaxPool2d(2))\n",
        "model.add_module('bn2', nn.BatchNorm2d(256))\n",
        "model.add_module('relu2', nn.ReLU())\n",
        "model.add_module('conv3', nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3))\n",
        "model.add_module('pool3', nn.MaxPool2d(2))\n",
        "model.add_module('bn3', nn.BatchNorm2d(512))\n",
        "model.add_module('relu3', nn.ReLU())\n",
        "model.add_module('flatten', Flatten())\n",
        "model.add_module('dense0', nn.Linear(2048, 1024))\n",
        "model.add_module('relu', nn.ReLU())\n",
        "model.add_module('dropout', nn.Dropout(0.3))\n",
        "model.add_module('dense1_logits', nn.Linear(1024, 10))\n",
        "\n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "train_loss_augmentation = []\n",
        "val_accuracy_augmentation = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A1gfq1zXg1t",
        "colab_type": "code",
        "outputId": "895ec599-a10b-4881-a326-1f0ae229dda9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "num_epochs = 100 # total amount of full passes over training data\n",
        "batch_size = 50  # number of samples processed in one SGD iteration\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # In each epoch, we do a full pass over the training data:\n",
        "    start_time = time.time()\n",
        "    model.train(True) # enable dropout / batch_norm training behavior\n",
        "    for (X_batch, y_batch) in train_batch_gen:\n",
        "        # train on batch\n",
        "        loss = compute_loss(X_batch, y_batch)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        train_loss_augmentation.append(loss.data.cpu().numpy())\n",
        "    print (num_epochs)    \n",
        "    model.train(False) # disable dropout / use averages for batch_norm\n",
        "    for X_batch, y_batch in val_batch_gen:\n",
        "        logits = model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
        "        y_pred = logits.max(1)[1].data\n",
        "        val_accuracy_augmentation.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
        "\n",
        "    print (num_epochs)\n",
        "    # Then we print the results for this epoch:\n",
        "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
        "        epoch + 1, num_epochs, time.time() - start_time))\n",
        "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
        "        np.mean(train_loss_augmentation[-len(train_dataset) // batch_size :])))\n",
        "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
        "        np.mean(val_accuracy_augmentation[-len(val_dataset) // batch_size :]) * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "100\n",
            "Epoch 1 of 100 took 20.887s\n",
            "  training loss (in-iteration): \t1.452166\n",
            "  validation accuracy: \t\t\t58.80 %\n",
            "100\n",
            "100\n",
            "Epoch 2 of 100 took 21.022s\n",
            "  training loss (in-iteration): \t1.026113\n",
            "  validation accuracy: \t\t\t66.74 %\n",
            "100\n",
            "100\n",
            "Epoch 3 of 100 took 20.847s\n",
            "  training loss (in-iteration): \t0.854680\n",
            "  validation accuracy: \t\t\t71.24 %\n",
            "100\n",
            "100\n",
            "Epoch 4 of 100 took 21.122s\n",
            "  training loss (in-iteration): \t0.731224\n",
            "  validation accuracy: \t\t\t72.96 %\n",
            "100\n",
            "100\n",
            "Epoch 5 of 100 took 20.956s\n",
            "  training loss (in-iteration): \t0.646118\n",
            "  validation accuracy: \t\t\t73.40 %\n",
            "100\n",
            "100\n",
            "Epoch 6 of 100 took 20.938s\n",
            "  training loss (in-iteration): \t0.569831\n",
            "  validation accuracy: \t\t\t75.96 %\n",
            "100\n",
            "100\n",
            "Epoch 7 of 100 took 21.024s\n",
            "  training loss (in-iteration): \t0.498521\n",
            "  validation accuracy: \t\t\t76.70 %\n",
            "100\n",
            "100\n",
            "Epoch 8 of 100 took 20.967s\n",
            "  training loss (in-iteration): \t0.437715\n",
            "  validation accuracy: \t\t\t76.80 %\n",
            "100\n",
            "100\n",
            "Epoch 9 of 100 took 20.943s\n",
            "  training loss (in-iteration): \t0.379712\n",
            "  validation accuracy: \t\t\t77.13 %\n",
            "100\n",
            "100\n",
            "Epoch 10 of 100 took 20.910s\n",
            "  training loss (in-iteration): \t0.330329\n",
            "  validation accuracy: \t\t\t77.50 %\n",
            "100\n",
            "100\n",
            "Epoch 11 of 100 took 20.876s\n",
            "  training loss (in-iteration): \t0.285710\n",
            "  validation accuracy: \t\t\t77.52 %\n",
            "100\n",
            "100\n",
            "Epoch 12 of 100 took 20.826s\n",
            "  training loss (in-iteration): \t0.242969\n",
            "  validation accuracy: \t\t\t78.65 %\n",
            "100\n",
            "100\n",
            "Epoch 13 of 100 took 20.897s\n",
            "  training loss (in-iteration): \t0.204779\n",
            "  validation accuracy: \t\t\t78.93 %\n",
            "100\n",
            "100\n",
            "Epoch 14 of 100 took 20.829s\n",
            "  training loss (in-iteration): \t0.174940\n",
            "  validation accuracy: \t\t\t78.75 %\n",
            "100\n",
            "100\n",
            "Epoch 15 of 100 took 20.873s\n",
            "  training loss (in-iteration): \t0.148542\n",
            "  validation accuracy: \t\t\t79.72 %\n",
            "100\n",
            "100\n",
            "Epoch 16 of 100 took 20.888s\n",
            "  training loss (in-iteration): \t0.123444\n",
            "  validation accuracy: \t\t\t79.15 %\n",
            "100\n",
            "100\n",
            "Epoch 17 of 100 took 20.851s\n",
            "  training loss (in-iteration): \t0.106952\n",
            "  validation accuracy: \t\t\t79.59 %\n",
            "100\n",
            "100\n",
            "Epoch 18 of 100 took 20.764s\n",
            "  training loss (in-iteration): \t0.084991\n",
            "  validation accuracy: \t\t\t79.06 %\n",
            "100\n",
            "100\n",
            "Epoch 19 of 100 took 20.980s\n",
            "  training loss (in-iteration): \t0.074852\n",
            "  validation accuracy: \t\t\t79.83 %\n",
            "100\n",
            "100\n",
            "Epoch 20 of 100 took 20.902s\n",
            "  training loss (in-iteration): \t0.060822\n",
            "  validation accuracy: \t\t\t80.39 %\n",
            "100\n",
            "100\n",
            "Epoch 21 of 100 took 20.845s\n",
            "  training loss (in-iteration): \t0.053166\n",
            "  validation accuracy: \t\t\t79.82 %\n",
            "100\n",
            "100\n",
            "Epoch 22 of 100 took 20.834s\n",
            "  training loss (in-iteration): \t0.044099\n",
            "  validation accuracy: \t\t\t79.38 %\n",
            "100\n",
            "100\n",
            "Epoch 23 of 100 took 20.922s\n",
            "  training loss (in-iteration): \t0.039007\n",
            "  validation accuracy: \t\t\t79.80 %\n",
            "100\n",
            "100\n",
            "Epoch 24 of 100 took 20.769s\n",
            "  training loss (in-iteration): \t0.035101\n",
            "  validation accuracy: \t\t\t80.16 %\n",
            "100\n",
            "100\n",
            "Epoch 25 of 100 took 20.826s\n",
            "  training loss (in-iteration): \t0.029248\n",
            "  validation accuracy: \t\t\t80.39 %\n",
            "100\n",
            "100\n",
            "Epoch 26 of 100 took 20.913s\n",
            "  training loss (in-iteration): \t0.025286\n",
            "  validation accuracy: \t\t\t80.54 %\n",
            "100\n",
            "100\n",
            "Epoch 27 of 100 took 20.851s\n",
            "  training loss (in-iteration): \t0.019901\n",
            "  validation accuracy: \t\t\t80.65 %\n",
            "100\n",
            "100\n",
            "Epoch 28 of 100 took 20.941s\n",
            "  training loss (in-iteration): \t0.017331\n",
            "  validation accuracy: \t\t\t80.39 %\n",
            "100\n",
            "100\n",
            "Epoch 29 of 100 took 20.866s\n",
            "  training loss (in-iteration): \t0.014645\n",
            "  validation accuracy: \t\t\t80.43 %\n",
            "100\n",
            "100\n",
            "Epoch 30 of 100 took 20.753s\n",
            "  training loss (in-iteration): \t0.013496\n",
            "  validation accuracy: \t\t\t80.65 %\n",
            "100\n",
            "100\n",
            "Epoch 31 of 100 took 20.760s\n",
            "  training loss (in-iteration): \t0.012613\n",
            "  validation accuracy: \t\t\t80.92 %\n",
            "100\n",
            "100\n",
            "Epoch 32 of 100 took 21.127s\n",
            "  training loss (in-iteration): \t0.009589\n",
            "  validation accuracy: \t\t\t81.15 %\n",
            "100\n",
            "100\n",
            "Epoch 33 of 100 took 20.977s\n",
            "  training loss (in-iteration): \t0.008512\n",
            "  validation accuracy: \t\t\t80.22 %\n",
            "100\n",
            "100\n",
            "Epoch 34 of 100 took 21.166s\n",
            "  training loss (in-iteration): \t0.007724\n",
            "  validation accuracy: \t\t\t80.81 %\n",
            "100\n",
            "100\n",
            "Epoch 35 of 100 took 21.097s\n",
            "  training loss (in-iteration): \t0.007368\n",
            "  validation accuracy: \t\t\t81.50 %\n",
            "100\n",
            "100\n",
            "Epoch 36 of 100 took 20.793s\n",
            "  training loss (in-iteration): \t0.006909\n",
            "  validation accuracy: \t\t\t81.09 %\n",
            "100\n",
            "100\n",
            "Epoch 37 of 100 took 20.991s\n",
            "  training loss (in-iteration): \t0.006741\n",
            "  validation accuracy: \t\t\t81.25 %\n",
            "100\n",
            "100\n",
            "Epoch 38 of 100 took 21.027s\n",
            "  training loss (in-iteration): \t0.005103\n",
            "  validation accuracy: \t\t\t80.79 %\n",
            "100\n",
            "100\n",
            "Epoch 39 of 100 took 20.760s\n",
            "  training loss (in-iteration): \t0.004519\n",
            "  validation accuracy: \t\t\t80.66 %\n",
            "100\n",
            "100\n",
            "Epoch 40 of 100 took 20.797s\n",
            "  training loss (in-iteration): \t0.003569\n",
            "  validation accuracy: \t\t\t81.47 %\n",
            "100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88b53f5be0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "Epoch 41 of 100 took 21.198s\n",
            "  training loss (in-iteration): \t0.003596\n",
            "  validation accuracy: \t\t\t81.16 %\n",
            "100\n",
            "100\n",
            "Epoch 42 of 100 took 20.778s\n",
            "  training loss (in-iteration): \t0.003998\n",
            "  validation accuracy: \t\t\t81.18 %\n",
            "100\n",
            "100\n",
            "Epoch 43 of 100 took 20.881s\n",
            "  training loss (in-iteration): \t0.003905\n",
            "  validation accuracy: \t\t\t81.17 %\n",
            "100\n",
            "100\n",
            "Epoch 44 of 100 took 21.051s\n",
            "  training loss (in-iteration): \t0.003494\n",
            "  validation accuracy: \t\t\t81.20 %\n",
            "100\n",
            "100\n",
            "Epoch 45 of 100 took 20.966s\n",
            "  training loss (in-iteration): \t0.002920\n",
            "  validation accuracy: \t\t\t81.60 %\n",
            "100\n",
            "100\n",
            "Epoch 46 of 100 took 20.961s\n",
            "  training loss (in-iteration): \t0.002718\n",
            "  validation accuracy: \t\t\t81.45 %\n",
            "100\n",
            "100\n",
            "Epoch 47 of 100 took 21.000s\n",
            "  training loss (in-iteration): \t0.002571\n",
            "  validation accuracy: \t\t\t81.42 %\n",
            "100\n",
            "100\n",
            "Epoch 48 of 100 took 21.012s\n",
            "  training loss (in-iteration): \t0.002608\n",
            "  validation accuracy: \t\t\t81.44 %\n",
            "100\n",
            "100\n",
            "Epoch 49 of 100 took 20.863s\n",
            "  training loss (in-iteration): \t0.002546\n",
            "  validation accuracy: \t\t\t81.21 %\n",
            "100\n",
            "100\n",
            "Epoch 50 of 100 took 20.888s\n",
            "  training loss (in-iteration): \t0.002230\n",
            "  validation accuracy: \t\t\t81.40 %\n",
            "100\n",
            "100\n",
            "Epoch 51 of 100 took 20.814s\n",
            "  training loss (in-iteration): \t0.002212\n",
            "  validation accuracy: \t\t\t81.82 %\n",
            "100\n",
            "100\n",
            "Epoch 52 of 100 took 20.980s\n",
            "  training loss (in-iteration): \t0.002057\n",
            "  validation accuracy: \t\t\t81.46 %\n",
            "100\n",
            "100\n",
            "Epoch 53 of 100 took 20.786s\n",
            "  training loss (in-iteration): \t0.001868\n",
            "  validation accuracy: \t\t\t81.18 %\n",
            "100\n",
            "100\n",
            "Epoch 54 of 100 took 20.772s\n",
            "  training loss (in-iteration): \t0.001780\n",
            "  validation accuracy: \t\t\t81.55 %\n",
            "100\n",
            "100\n",
            "Epoch 55 of 100 took 20.664s\n",
            "  training loss (in-iteration): \t0.001580\n",
            "  validation accuracy: \t\t\t81.73 %\n",
            "100\n",
            "100\n",
            "Epoch 56 of 100 took 20.873s\n",
            "  training loss (in-iteration): \t0.001486\n",
            "  validation accuracy: \t\t\t81.58 %\n",
            "100\n",
            "100\n",
            "Epoch 57 of 100 took 20.752s\n",
            "  training loss (in-iteration): \t0.001727\n",
            "  validation accuracy: \t\t\t81.32 %\n",
            "100\n",
            "100\n",
            "Epoch 58 of 100 took 20.764s\n",
            "  training loss (in-iteration): \t0.001962\n",
            "  validation accuracy: \t\t\t81.50 %\n",
            "100\n",
            "100\n",
            "Epoch 59 of 100 took 20.858s\n",
            "  training loss (in-iteration): \t0.001664\n",
            "  validation accuracy: \t\t\t81.82 %\n",
            "100\n",
            "100\n",
            "Epoch 60 of 100 took 20.757s\n",
            "  training loss (in-iteration): \t0.001625\n",
            "  validation accuracy: \t\t\t81.35 %\n",
            "100\n",
            "100\n",
            "Epoch 61 of 100 took 20.732s\n",
            "  training loss (in-iteration): \t0.001533\n",
            "  validation accuracy: \t\t\t81.19 %\n",
            "100\n",
            "100\n",
            "Epoch 62 of 100 took 20.782s\n",
            "  training loss (in-iteration): \t0.001432\n",
            "  validation accuracy: \t\t\t81.16 %\n",
            "100\n",
            "100\n",
            "Epoch 63 of 100 took 20.847s\n",
            "  training loss (in-iteration): \t0.001359\n",
            "  validation accuracy: \t\t\t81.38 %\n",
            "100\n",
            "100\n",
            "Epoch 64 of 100 took 20.805s\n",
            "  training loss (in-iteration): \t0.001424\n",
            "  validation accuracy: \t\t\t81.45 %\n",
            "100\n",
            "100\n",
            "Epoch 65 of 100 took 20.831s\n",
            "  training loss (in-iteration): \t0.001470\n",
            "  validation accuracy: \t\t\t81.43 %\n",
            "100\n",
            "100\n",
            "Epoch 66 of 100 took 20.795s\n",
            "  training loss (in-iteration): \t0.001122\n",
            "  validation accuracy: \t\t\t81.81 %\n",
            "100\n",
            "100\n",
            "Epoch 67 of 100 took 20.948s\n",
            "  training loss (in-iteration): \t0.001085\n",
            "  validation accuracy: \t\t\t81.54 %\n",
            "100\n",
            "100\n",
            "Epoch 68 of 100 took 20.810s\n",
            "  training loss (in-iteration): \t0.000930\n",
            "  validation accuracy: \t\t\t81.59 %\n",
            "100\n",
            "100\n",
            "Epoch 69 of 100 took 20.793s\n",
            "  training loss (in-iteration): \t0.001240\n",
            "  validation accuracy: \t\t\t81.39 %\n",
            "100\n",
            "100\n",
            "Epoch 70 of 100 took 20.863s\n",
            "  training loss (in-iteration): \t0.001132\n",
            "  validation accuracy: \t\t\t81.31 %\n",
            "100\n",
            "100\n",
            "Epoch 71 of 100 took 21.020s\n",
            "  training loss (in-iteration): \t0.001083\n",
            "  validation accuracy: \t\t\t81.30 %\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wYqDmEKXg1u",
        "colab_type": "text"
      },
      "source": [
        "We need for test data __only normalization__, not cropping and rotation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c6Xy4-NXg1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(means, stds),\n",
        "])\n",
        "\n",
        "test_dataset = <YOUR CODE>\n",
        "test_batch_gen = <YOUR CODE>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-afRzOI5qcLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.train(False) # disable dropout / use averages for batch_norm\n",
        "test_batch_acc = []\n",
        "for X_batch, y_batch in test_batch_gen:\n",
        "    logits = model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
        "    y_pred = logits.max(1)[1].data\n",
        "    test_batch_acc.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
        "\n",
        "\n",
        "test_accuracy = np.mean(test_batch_acc)\n",
        "    \n",
        "print(\"Final results:\")\n",
        "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
        "    test_accuracy * 100))\n",
        "\n",
        "if test_accuracy * 100 > 70:\n",
        "    print(\"U'r freakin' amazin'!\")\n",
        "elif test_accuracy * 100 > 50:\n",
        "    print(\"Achievement unlocked: 110lvl Warlock!\")\n",
        "elif test_accuracy * 100 > 40:\n",
        "    print(\"Achievement unlocked: 80lvl Warlock!\")\n",
        "elif test_accuracy * 100 > 30:\n",
        "    print(\"Achievement unlocked: 70lvl Warlock!\")\n",
        "elif test_accuracy * 100 > 20:\n",
        "    print(\"Achievement unlocked: 60lvl Warlock!\")\n",
        "else:\n",
        "    print(\"We need more magic! Follow instructons below\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfg5uqjjoUit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Analyze your model here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7N3sd2tu7LH",
        "colab_type": "text"
      },
      "source": [
        "Feel free to play with the model to get better score :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPDbrHRQu5u4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}